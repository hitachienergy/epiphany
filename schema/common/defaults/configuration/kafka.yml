---
kind: configuration/kafka
title: Kafka
name: default
specification:
  enabled: True
  # javax_net_debug: all # uncomment to activate debugging, other debug options: https://colinpaice.blog/2020/04/05/using-java-djavax-net-debug-to-examine-data-flows-including-tls/
  security:
    ssl:
      enabled: False
      port: 9093
      server:
        local_cert_download_path: kafka-certs
        keystore_location: /var/private/ssl/kafka.server.keystore.jks
        truststore_location: /var/private/ssl/kafka.server.truststore.jks
        cert_validity: 365
        passwords:
          keystore: PasswordToChange
          truststore: PasswordToChange
          key: PasswordToChange
      endpoint_identification_algorithm: HTTPS
      client_auth: required
    inter_broker_protocol: PLAINTEXT
    authorization:
      enabled: False
      authorizer_class_name: kafka.security.auth.SimpleAclAuthorizer
      allow_everyone_if_no_acl_found: False
      super_users:
        - tester01
        - tester02
      users:
        - name: test_user
          topic: test_topic
    authentication:
      enabled: False
      authentication_method: certificates
      sasl_mechanism_inter_broker_protocol:
      sasl_enabled_mechanisms: PLAIN
  port: 9092

  # Availability
  min_insync_replicas: 2 # Minimum number of replicas that must acknowledge data was received (ack write)
  default_replication_factor: 3 # Recommended value for production is 3
  offsets_topic_replication_factor: 3 # Minimum number of offsets topic (3 for HA)

  partitions: 2 # 100 x brokers x replicas for reasonable size cluster. Small clusters can be less
  log_retention_hours: 168 # (7 days) The minimum age of a log file to be eligible for deletion due to age
  log_retention_bytes: 2147483648 # (2 GiB) -1 is no size limit only a time limit (log_retention_hours). This limit is enforced at the partition level, multiply it by the number of partitions to compute the topic retention in bytes.
  offset_retention_minutes: 10080 # Offsets older than this retention period will be discarded
  heap_opts: "-Xmx2G -Xms2G" # Values for VM with 8 GiB of RAM (based on https://bitnami.com/stack/kafka/cloud/azure)
  jmx_opts:
  max_incremental_fetch_session_cache_slots: 1000
  controlled_shutdown_enable: true
  group: kafka
  user: kafka
  conf_dir: /opt/kafka/config
  data_dir: /var/lib/kafka
  log_dir: /var/log/kafka
  socket_settings:
    network_threads: 3 # The number of threads handling network requests
    io_threads: 8 # The number of threads doing disk I/O
    send_buffer_bytes: 102400 # The send buffer (SO_SNDBUF) used by the socket server
    receive_buffer_bytes: 102400 # The receive buffer (SO_RCVBUF) used by the socket server
    request_max_bytes: 104857600 # The maximum size of a request that the socket server will accept (protection against OOM)
  zookeeper_set_acl: false
  zookeeper_hosts: "{{ groups['zookeeper']|join(':2181,') }}:2181"
  jmx_exporter_user: jmx-exporter
  jmx_exporter_group: jmx-exporter
  prometheus_jmx_exporter_web_listen_port: 7071
  prometheus_jmx_config: /opt/kafka/config/jmx-kafka.config.yml
  prometheus_config_dir: /etc/prometheus
  prometheus_kafka_jmx_file_sd_labels:
    "job": "jmx-kafka"
